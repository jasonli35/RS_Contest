{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "def readGz(path):\n",
    "  for l in gzip.open(path, 'rt'):\n",
    "    yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "  f = gzip.open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')\n",
    "\n",
    "all_ratings = []\n",
    "for user,book,r in readCSV(\"train_Interactions.csv.gz\"):\n",
    "  all_ratings.append([user,book,float(r)])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_all =  0.14  n_factors =  0 MSE =  1.4559047720115021\n",
      "reg_all =  0.11  n_factors =  0 MSE =  1.453819628817556\n",
      "reg_all =  0.12  n_factors =  0 MSE =  1.452639008455994\n",
      "reg_all =  0.13  n_factors =  0 MSE =  1.453475874510454\n",
      "reg_all =  0.02  n_factors =  0 MSE =  1.4575371623908342\n",
      "reg_all =  0.14  n_factors =  1 MSE =  1.452300258490642\n",
      "reg_all =  0.11  n_factors =  1 MSE =  1.4541993770297137\n",
      "reg_all =  0.12  n_factors =  1 MSE =  1.4531866081373106\n",
      "reg_all =  0.13  n_factors =  1 MSE =  1.455387113128535\n",
      "reg_all =  0.02  n_factors =  1 MSE =  1.463199911374528\n",
      "bestMSE =  1.452300258490642\n",
      "best parameter n factor =  1  reg =  0.14\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVDpp, accuracy\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from surprise.model_selection.split import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file(\"\" + \"train_Interactions.csv\", reader=reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# data = Dataset.load_from_df(df_ratings, reader=reader)\n",
    "bestMSE = 2\n",
    "best_i = 0\n",
    "best_u = 0\n",
    "\n",
    "i_mse = defaultdict(list)\n",
    "u_mse = defaultdict(list)\n",
    "\n",
    "for i in [0,1]:\n",
    "    for u in [0.14,0.11, 0.12,0.13,0.02]:\n",
    "\n",
    "        kf = KFold(n_splits=5)\n",
    "\n",
    "        accur = []\n",
    "\n",
    "        for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "            model = SVDpp(n_factors = i, reg_all = u)\n",
    "            model.fit(trainset)\n",
    "            predictions = model.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "            accur.append(accuracy.mse(predictions, verbose=False))\n",
    "\n",
    "        accur = np.array(accur)\n",
    "    \n",
    "        mse_current = np.mean(accur)\n",
    "        if(mse_current < bestMSE):\n",
    "            best_i = i\n",
    "            best_u = u\n",
    "            \n",
    "            bestMSE = mse_current\n",
    "\n",
    "        print(\"reg_all = \", u, \" n_factors = \", i, \"MSE = \", mse_current)\n",
    "        i_mse[i].append(mse_current)\n",
    "        u_mse[u].append(mse_current)\n",
    "\n",
    "print(\"bestMSE = \", bestMSE)\n",
    "print(\"best parameter n factor = \", best_i, \" reg = \", best_u)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.4546752892372683, 1: 1.455654653632146}\n",
      "{0.12: 1.4529128082966523, 0.11: 1.4540095029236348, 0.14: 1.454102515251072, 0.13: 1.4544314938194944, 0.02: 1.460368536882681}\n"
     ]
    }
   ],
   "source": [
    "avg_i = defaultdict(float)\n",
    "avg_u = defaultdict(float)\n",
    "for i in i_mse:\n",
    "    avg_i[i] = sum(i_mse[i]) / len(i_mse[i])\n",
    "\n",
    "for u in u_mse:\n",
    "    avg_u[u] = sum(u_mse[u]) / len(u_mse[u])\n",
    "\n",
    "print(dict(sorted(avg_i.items(), key=lambda item: item[1])))\n",
    "print(dict(sorted(avg_u.items(), key=lambda item: item[1])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVDpp at 0x7f84e20fc520>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.000000001)\n",
    "model = SVDpp(reg_all=0.11,n_factors=0)\n",
    "model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x7f93ca08cac0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Trainset' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m userIDs \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m itemIDs \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m trainset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     u \u001b[39m=\u001b[39m d[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     i \u001b[39m=\u001b[39m d[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Trainset' object is not iterable"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "userIDs = defaultdict(int)\n",
    "itemIDs = defaultdict(int)\n",
    "for d in trainset:\n",
    "    u = d[0]\n",
    "    i = d[1]\n",
    "    if(u not in userIDs):\n",
    "        userIDs[u] = len(userIDs)\n",
    "    if(i not in itemIDs):\n",
    "        itemIDs[i] = len(itemIDs)\n",
    "\n",
    "len(userIDs)\n",
    "len(itemIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  1.7256470083265885 for k =  1\n",
      "MSE =  1.7301639316147357 for k =  2\n",
      "MSE =  1.725289218377765 for k =  3\n",
      "MSE =  1.7252584805389717 for k =  4\n",
      "MSE =  1.7295875615159824 for k =  5\n",
      "MSE =  1.725320719379112 for k =  6\n",
      "MSE =  1.7264886989580035 for k =  10\n",
      "MSE =  1.7257932110429341 for k =  50\n"
     ]
    }
   ],
   "source": [
    "# LFM using tensorflow\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "\n",
    "userIDs = defaultdict(int)\n",
    "itemIDs = defaultdict(int)\n",
    "interactions = []\n",
    "\n",
    "for d in all_ratings:\n",
    "    u = d[0]\n",
    "    i = d[1]\n",
    "    r = d[2]\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    interactions.append((u,i,r))\n",
    "\n",
    "random.shuffle(interactions)\n",
    "\n",
    "\n",
    "nTrain = int(len(interactions) * 0.9)\n",
    "nTest = len(interactions) - nTrain\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsTest = interactions[nTrain:]\n",
    "\n",
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "for u,i,r in interactionsTrain:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)\n",
    "mu = sum([r for _,_,r in interactionsTrain]) / len(interactionsTrain)\n",
    "\n",
    "\n",
    "class LatentFactorModel(tf.keras.Model):\n",
    "    def __init__(self, mu, K, lamb):\n",
    "        super(LatentFactorModel, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i] +\\\n",
    "            tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2) +\\\n",
    "                            tf.reduce_sum(self.gammaU**2) +\\\n",
    "                            tf.reduce_sum(self.gammaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i +\\\n",
    "               tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)\n",
    "\n",
    "\n",
    "def trainingStep(model, interactions_ts):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions_ts)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()\n",
    "\n",
    "\n",
    "for k in [1,2,3,4,5,6,10,50]:\n",
    "    modelLFM = None\n",
    "    modelLFM = LatentFactorModel(mu, k, 20)\n",
    "    for i in range(100):\n",
    "        obj = trainingStep(modelLFM, interactionsTrain)\n",
    "        # if (i % 10 == 9): print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))\n",
    "\n",
    "    MSE = 0\n",
    "    for (u,i,r) in interactionsTest:\n",
    "        # u,i,r = interactionsTest[0]\n",
    "        predict = modelLFM.predict(userIDs[u], itemIDs[i]).numpy()\n",
    "        MSE += (predict - r) ** 2\n",
    "    MSE /= len(interactionsTest)\n",
    "\n",
    "    print(\"MSE = \", MSE, \"for k = \", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLFM = LatentFactorModel(mu, 4, 20)\n",
    "def getMSE_lfm():\n",
    "    MSE = 0\n",
    "    for (u,i,r) in interactionsTest:\n",
    "        # u,i,r = interactionsTest[0]\n",
    "        predict = float(modelLFM.predict(userIDs[u], itemIDs[i]))\n",
    "        MSE += (predict - r) ** 2\n",
    "    MSE /= len(interactionsTest)\n",
    "    return MSE\n",
    "\n",
    "\n",
    "has_improved = True\n",
    "pre_ite_mse = getMSE_lfm()\n",
    "post_ite_mse = 0\n",
    "\n",
    "iteraction = 0\n",
    "while(iteraction < 100):\n",
    "    obj = trainingStep(modelLFM, interactions)\n",
    "    # post_ite_mse = getMSE_lfm()\n",
    "    # if(pre_ite_mse - post_ite_mse <= 0):\n",
    "    #     has_improved = False\n",
    "    # pre_ite_mse = post_ite_mse\n",
    "    iteraction += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7253735009883755"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMSE_lfm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  0.6489271233778804\n"
     ]
    }
   ],
   "source": [
    "MSE = 0\n",
    "for (u,i,r) in interactionsTest:\n",
    "        # u,i,r = interactionsTest[0]\n",
    "    predict = float(modelLFM.predict(userIDs[u], itemIDs[i]))\n",
    "    MSE += (predict - r) ** 2\n",
    "MSE /= len(interactionsTest)\n",
    "print(\"MSE = \", MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"./pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    # Logic...\n",
    "    \n",
    "    # _ = predictions.write(u + ',' + g + ',' + str(predict_rating(u,g)) + '\\n')\n",
    "\n",
    "    prediction = model.predict(u,g).est\n",
    "    # prediction = float(modelLFM.predict(userIDs[u], itemIDs[i]))\n",
    "\n",
    "    # prediction = modelLFM.predict(userIDs[u], itemIDs[i]).numpy()\n",
    "    # print(prediction)\n",
    "    if(prediction < 0):\n",
    "        prediction = 0\n",
    "    if(prediction > 5):\n",
    "        prediction = 5\n",
    "\n",
    "\n",
    "    _ = predictions.write(u + ',' + g + ',' + str(prediction) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8329050540924072"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(modelLFM.predict(2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "random.shuffle(all_ratings)\n",
    "cutoff_index = int(len(all_ratings) * 0.2)\n",
    "trainset = all_ratings[:cutoff_index]\n",
    "testset = all_ratings[cutoff_index:]\n",
    "\n",
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "\n",
    "# for d in train_entries:\n",
    "#     itemsPerUser[d[0]].append(d[1])\n",
    "#     usersPerItem[d[1]].append(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m best_mse \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m \u001b[39m# for l in range(1, 20):\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39m#     lamb = l / 10\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m \u001b[39m#     cur_mse = find_mse_given_lamb(lamb)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m \u001b[39m#     if(cur_mse < best_mse):\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m \u001b[39m#         best_mse = cur_mse\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m \u001b[39m#         best_lam = lamb\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m find_mse_given_lamb(\u001b[39m1.0\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpredictions_Rating.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m./pairs_Rating.csv\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "\u001b[1;32m/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mwhile\u001b[39;00m(converge \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     old_objective \u001b[39m=\u001b[39m findLost(lamb)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     iterate(lamb)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     new_objective \u001b[39m=\u001b[39m findLost(lamb)\n",
      "\u001b[1;32m/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m complexity \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m u \u001b[39min\u001b[39;00m betaU:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     complexity \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m betaU[u] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m betaI:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jasonli/Downloads/assignment158_makeup/rating_prediction.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     complexity \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m betaI[i] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# Hours played prediction                        #\n",
    "#################################################\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "trainRating = [float(r[2]) for r in trainset]\n",
    "globalAverage = sum(trainRating) * 1.0 / len(trainRating)\n",
    " \n",
    "### Question 6\n",
    "betaU = model.bu\n",
    "betaI = model.bi\n",
    "\n",
    "ratings = defaultdict(float)\n",
    "all_user_set = set()\n",
    "all_item_set = set()\n",
    "\n",
    "for d in trainset:\n",
    "    item = d[1]\n",
    "    user = d[0]\n",
    "    ratings[(user, item)] = float(d[2])\n",
    "    all_user_set.add(user)\n",
    "    all_item_set.add(item)\n",
    "\n",
    "\n",
    "alpha = globalAverage # Could initialize anywhere, this is a guess\n",
    "\n",
    "def iterate(lamb):\n",
    "\n",
    "    alpha = 0\n",
    "    for allKeys in ratings:\n",
    "        u = allKeys[0]\n",
    "        i = allKeys[1]\n",
    "        alpha += ratings[(u,i)] - (betaU[u] + betaI[i])\n",
    "    alpha /= len(ratings)\n",
    "\n",
    "    for user in all_user_set:\n",
    "        betaU[user] = 0\n",
    "        for i in itemsPerUser[user]:\n",
    "            betaU[user] += ratings[(user, i)] - (alpha + betaI[i])\n",
    "        betaU[user] /= lamb + len(itemsPerUser[user])\n",
    "\n",
    "    for item in all_item_set:\n",
    "        betaI[item] = 0\n",
    "        for u in usersPerItem[item]:\n",
    "            betaI[item] += ratings[(u, item)] - (alpha + betaU[u])\n",
    "        betaI[item] /= lamb + len(usersPerItem[item])\n",
    "\n",
    "    \n",
    "\n",
    "def findLost(lamb):\n",
    "    lost = 0\n",
    "    for allKeys in testset:\n",
    "        u = allKeys[0]\n",
    "        i = allKeys[1]\n",
    "        prediction = 0\n",
    "        if(u not in betaU):\n",
    "            if(i in betaI):\n",
    "                prediction = alpha + betaI[i]\n",
    "            else:\n",
    "                prediction = alpha\n",
    "        elif(i not in betaI):\n",
    "            prediction = alpha + betaU[u]\n",
    "        else:\n",
    "            prediction =  alpha + betaU[u] + betaI[i]\n",
    "\n",
    "        lost += (prediction - allKeys[2]) ** 2\n",
    "    complexity = 0\n",
    "    for u in betaU:\n",
    "        complexity += betaU[u] ** 2\n",
    "    for i in betaI:\n",
    "        complexity += betaI[i] ** 2\n",
    "    lost += lamb * complexity\n",
    "    return lost\n",
    "\n",
    "def predict_rating(predict_user, predict_item):\n",
    "    if(predict_item not in betaI):\n",
    "        if(predict_user in betaU):\n",
    "            prediction = alpha + betaU[predict_user]\n",
    "        else:\n",
    "            prediction = alpha\n",
    "    elif(predict_user not in betaU):\n",
    "        prediction = betaI[predict_item]\n",
    "    else:\n",
    "        prediction = alpha + betaU[predict_user] + betaI[predict_item]\n",
    "    \n",
    "    return prediction\n",
    "    \n",
    "\n",
    "def find_mse_given_lamb(lamb):\n",
    "\n",
    "    for u in itemsPerUser:\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for g in usersPerItem:\n",
    "        betaI[g] = 0\n",
    "\n",
    "    converge = False\n",
    "    count = 0\n",
    "    while(converge == False):\n",
    "        old_objective = findLost(lamb)\n",
    "        iterate(lamb)\n",
    "        new_objective = findLost(lamb)\n",
    "        if(old_objective - new_objective < 0 ):\n",
    "            converge = True\n",
    "        count += 1\n",
    "    validMSE = 0\n",
    "    for each_val_item in valid_entries:\n",
    "        actual_label = each_val_item[2]\n",
    "        predict_user = each_val_item[0]\n",
    "        predict_item = each_val_item[1]\n",
    "\n",
    "        prediction = predict_rating(predict_user, predict_item)\n",
    "\n",
    "        \n",
    "        validMSE += (actual_label - prediction) ** 2\n",
    "    validMSE /= len(valid_entries)\n",
    "\n",
    "    return validMSE\n",
    "\n",
    "    \n",
    "\n",
    "### Question 7\n",
    "# betaUs = [(betaU[u], u) for u in betaU]\n",
    "# betaIs = [(betaI[i], i) for i in betaI]\n",
    "# betaUs.sort()\n",
    "# betaIs.sort()\n",
    "\n",
    "# print(\"Maximum betaU = \" + str(betaUs[-1][1]) + ' (' + str(betaUs[-1][0]) + ')')\n",
    "# print(\"Maximum betaI = \" + str(betaIs[-1][1]) + ' (' + str(betaIs[-1][0]) + ')')\n",
    "# print(\"Minimum betaU = \" + str(betaUs[0][1]) + ' (' + str(betaUs[0][0]) + ')')\n",
    "# print(\"Minimum betaI = \" + str(betaIs[0][1]) + ' (' + str(betaIs[0][0]) + ')')\n",
    "\n",
    "\n",
    "\n",
    "best_lam = 0\n",
    "best_mse = 10\n",
    "\n",
    "# for l in range(1, 20):\n",
    "#     lamb = l / 10\n",
    "#     cur_mse = find_mse_given_lamb(lamb)\n",
    "#     if(cur_mse < best_mse):\n",
    "#         best_mse = cur_mse\n",
    "#         best_lam = lamb\n",
    "\n",
    "\n",
    "find_mse_given_lamb(1.0)\n",
    "\n",
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"./pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    # Logic...\n",
    "    \n",
    "    # _ = predictions.write(u + ',' + g + ',' + str(predict_rating(u,g)) + '\\n')\n",
    "\n",
    "    prediction = model.predict(u,g).est\n",
    "    # print(prediction)\n",
    "\n",
    "\n",
    "    _ = predictions.write(u + ',' + g + ',' + str(prediction) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse158",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
